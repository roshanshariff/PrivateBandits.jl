\documentclass{article}
\usepackage[utf8]{inputenc}

\title{Differentially Private Contextual Bandits}
\author{Roshan Shariff}

\usepackage[semibold]{libertine} % a bit lighter than Times--no osf in math
\usepackage[T1]{fontenc} % best for Western European languages
\usepackage{textcomp} % required to get special symbols
\usepackage[varqu,varl]{inconsolata} % a typewriter font must be defined
\usepackage{amsmath,mathtools}
\usepackage{amsthm,thmtools,thm-restate}
\usepackage{amssymb} % loads amsfonts
\usepackage{nicefrac}
\usepackage[libertine,cmintegrals,bigdelims,vvarbb]{newtxmath} % replaces some amssymb symbols
\usepackage[scr=rsfso]{mathalfa} % Use rsfso to provide mathscr
\usepackage{dsfont}
\usepackage{bm} % load after all math to give access to bold math

\usepackage{microtype}
\usepackage[inline,shortlabels]{enumitem}
\usepackage{setspace}
\usepackage{tikz-cd}
\usepackage{booktabs}
\usepackage[boxed]{algorithm}
\usepackage{algpseudocode}
\usepackage{fullpage}
\usepackage{color}
\newcommand{\os}[1]{\textcolor{red}{Or's comment:~}#1}
%\usepackage{dblfloatfix}

%% Bibliography/\usepackage[round,colon]{natbib}

%% Cross-references
\usepackage{varioref}
\usepackage[hidelinks]{hyperref}
\usepackage[capitalise]{cleveref}

%% To-do notes
\usepackage[obeyFinal]{todonotes}

% \newcommand{\tinytodo}[2][]{\todo[size=\tiny]{#2}}
\newcommand{\tinytodo}[2][]{\todo[size=\tiny, #1]{\begin{spacing}{1.0}#2\end{spacing}}}
\newcommand{\RStodo}[2][]{\tinytodo[color=red!20, #1]{R:\@#2}} % Roshan
\newcommand{\OStodo}[2][]{\tinytodo[color=blue!20, #1]{Cs: #2}} % Or
\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

%% Macros

\newcommand{\wildcard}{\mathinner{\,{\cdot}\,}}
\newcommand{\defeq}{\coloneq}
\newcommand{\eqdef}{\eqcolon}
\newcommand{\inv}[1]{#1^{-1}}
\newcommand{\Real}{\mathds{R}}
\newcommand{\Nat}{\mathds{N}}
\newcommand{\Int}{\mathds{Z}}
\newcommand{\mgf}{\mathrm{mgf}}
\newcommand{\UCB}{\operatorname{UCB}}
\renewcommand\mid{\mathinner{\vert}}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator{\tr}{tr}

\newcommand\given[1][\delimsize]{%
  \providecommand{\delimsize}{}
  \nonscript\:#1\vert\allowbreak\nonscript\:\mathopen{}
}

\DeclarePairedDelimiter{\abs}||
\DeclarePairedDelimiter{\paren}()
\DeclarePairedDelimiter{\brck}{[}{]}
\DeclarePairedDelimiter{\set}\{\}
\DeclarePairedDelimiterX{\innerp}[2]\langle\rangle{#1,#2}
\DeclarePairedDelimiterXPP{\Prob}[1]{\mathds{P}}(){}{#1}
\DeclarePairedDelimiterXPP{\PrSet}[1]{\mathds{P}}\{\}{}{#1}
\DeclarePairedDelimiterXPP{\Ex}[1]{\mathds{E}}{[}{]}{}{#1}
\DeclarePairedDelimiterXPP{\Exx}[2]{\mathds{E}_{#1}}{[}{]}{}{#2}
\DeclarePairedDelimiterXPP{\Var}[1]{\mathrm{Var}}{[}{]}{}{#1}
\DeclarePairedDelimiterXPP{\One}[1]{\mathds{1}}\{\}{}{#1}
\DeclarePairedDelimiterXPP{\norm}[2]{}\Vert\Vert{_{#1}}{#2}

%% Other symbols
\newcommand{\transp}[1]{#1^\intercal}
\newcommand{\Dset}[1]{\mathcal{D}_{#1}}
\newcommand{\Cset}[1]{\mathcal{C}_{#1}}

% Theorem environments

\declaretheorem[style=definition]{assumption}
\declaretheorem[style=definition]{theorem}
\declaretheorem[style=definition]{lemma}
\declaretheorem[style=definition]{corollary}

\Crefname{assumption}{Assumption}{Assumptions}

%%%%%%%%%%%%%%%%%%%%%G%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\onehalfspacing

\begin{document}

\maketitle

\todo[inline]{Consider non-contextual bandits; only the rewards are
  private.  Does this help with the counter-example against optimism
  in Tor's paper?}

\section{The Contextual Linear Bandit Framework}

In the stochastic linear bandit framework, at each round:
\begin{enumerate}
\item The agent receives a \emph{decision set} $\mathcal{D}_t \subset
  \Real^d$.
\item The agent chooses an \emph{action} $X_t \in \mathcal{D}_t$.
\item The agent receives a \emph{reward} $Y_t = \innerp{X_t}{\theta^*} + \eta_t$.
\end{enumerate}
The vector $\theta^*\in\Real^d$ is an unknown parameter of the
environment.

\begin{assumption}[Subgaussian noise]\label{assumption:subgaussian-noise}
  We denote by
  $\mathcal{F}_t =
  \sigma(\mathcal{D}_1,X_1,Y_1,\dotsc,\mathcal{D}_{t-1},X_{t-1},Y_{t-1},\mathcal{D}_t,X_t)$
  all the information available just before the noise $\eta_t$ is
  observed.  We assume that $\eta_t$ is \emph{conditionally
    1-subgaussian:}
  \begin{align*}
    \Ex{\exp(\lambda\eta_t)\given \mathcal{F}_t} &\le \exp(\lambda^2/2),
    &\text{for all } \lambda\in\Real.
  \end{align*}
\end{assumption}
\section{Linear UCB}

We start by analyzing the LinUCB algorithm (also known as OFUL ---
Optimism in the Face of Uncertainty--Linear).  The algorithm is as follows

\begin{algorithm}
  \caption{Linear UCB}\label{alg:linucb}
  \begin{algorithmic}
    \For{$t \in 1,2,\dotsc,n$}
    \State Receive decision set $\Dset{t} \subset \Real^d$
    \State $\Cset{t} \gets \Cset{t}(X_1,Y_1,\dotsc,X_{t-1},Y_{t-1})$
    \State $X_t \gets \argmax_{x\in\Dset{t}}
    \max_{\theta\in\Cset{t}} \innerp{x}{\theta}$
    \State Choose action $X_t$ and receive reward $Y_t$
    \EndFor
  \end{algorithmic}
\end{algorithm}

We will show a generic regret bound that will depend on certain
assumptions about the decision sets $\Dset{t} \subset \Real^d$,
unknown parameter vector $\theta^*\in\Real^d$, and confidence sets
$\Cset{t}$.

\begin{assumption}\label{assumption:linucb}
  We assume that
  \begin{itemize}
  \item The mean reward is bounded: $\abs{\innerp{x}{\theta^*}} \le B$
    for any $x\in\bigcup_t\Dset{t}$.
  \item The actions are bounded: $\norm{}{x} \le L$ for all
    $x\in\bigcup_t\Dset{t}$.
  \item \os{This isn't an assumption. This is more of the nature of things you want to prove. My suggestion: call a sequence of $\beta$s and $V$s $\delta$-good if for any $t$ and blah-blah it holds that...} The confidence intervals hold with high probability: with
    probability $1-\delta$, for all $t\in[n]$, $x\in\Dset{t}$,
    \begin{align*}
      \UCB_t(x) &\ge \innerp{x}{\theta^*} \ge \UCB_t(x) - 2\sqrt{\beta_{t-1}}\norm{\inv{V_{t-1}}}{x}
      \shortintertext{where}
      \UCB_t(x) &\defeq \max_{\theta\in\Cset{t}} \innerp{x}{\theta}
    \end{align*}
    and $\beta_0,\dotsc,\beta_{n-1}\in\Real$ is a non-decreasing sequence
    with $\beta_{n-1} \ge B^2$ and $0 \prec V_0,\dotsc,V_{n-1} \in
    \Real^{d \times d}$ is a sequence of symmetric positive definite matrices.
  \end{itemize}
\end{assumption}

\begin{lemma}\label{lemma:linucb-regret}
  Suppose \cref{assumption:linucb} holds with some sequences
  ${(\beta_t)}_t$ and ${(V_t)}_t$.  Then, with probability $1-\delta$
  the pseudo-regret of Linear UCB satisfies
  \begin{align*}
    \widehat{R}_n &\le \sqrt{4n\beta_{n-1} \sum_{t=1}^n (1 \wedge \norm{\inv{V_{t-1}}}{X_t}^2)}.
  \end{align*}

  \begin{proof}
    We have assumed that the confidence intervals hold with
    probability $1-\delta$, so it suffices to restrict ourselves to
    this event.  Let
    $r_t = \max_{x\in\Dset{t}} \innerp{x-X_t}{\theta^*}$ be the
    immediate pseudo-regret suffered at round $t\in[n]$.

    Let $X_t^* = \argmax_{x\in\Dset{t}}\innerp{x}{\theta^*}$ be an optimal
    action for round $t$.  We know that the confidence interval holds
    for $X_t^*$, and also that we choose the action with highest UCB, so
    \begin{align*}
      \innerp{X_t^*}{\theta^*} &\le \UCB_t(X_t^*) \le \UCB_t(X_t).
    \end{align*}
    Since the lower confidence bound also holds by our assumption,
    \begin{align*}
      \innerp{X_t}{\theta^*} &\ge \UCB_t(X_t) - 2\sqrt{\beta_{t-1}}\norm{\inv{V_{t-1}}}{X_t}.
    \end{align*}
    Combining these inequalities we get
    \begin{align*}
      r_t &= \innerp{X_t^*}{\theta^*} - \innerp{X_t}{\theta^*} \\
         &\le \UCB_t(X_t) - \innerp{X_t}{\theta^*} \\
         &\le 2\sqrt{\beta_{t-1}}\norm{\inv{V_{t-1}}}{X_t}.
    \end{align*}
    Since we assumed that the mean absolute reward is bounded by $B$
    we also get that $r_t \le 2B$, and since $\beta_n \ge \beta_t \vee B$
    we have
    \begin{align*}
      r_t &\le 2B \wedge 2\sqrt{\beta_{t-1}}\norm{\inv{V_{t-1}}}{X_t}
           \le 2\sqrt{\beta_{n-1}} (1 \wedge \norm{\inv{V_{t-1}}}{X_t}).
    \end{align*}

    Now we apply Jensen's inequality as follows:
    \begin{align*}
      \widehat{R}_n^2 &= n^2 \paren[\Big]{\sum_{t=1}^n \frac{r_t}{n}}^2
                      \le n^2 \sum_{t=1}^n \frac{r_t^2}{n} = n\sum_{t=1}^nr_t^2 \\
      \widehat{R}_n &\le \sqrt{n\sum_{t=1}^n r_t^2} \\
                    &= \sqrt{4n\beta_{n-1} \sum_{t=1}^n (1 \wedge \norm{\inv{V_{t-1}}}{X_t}^2)}.
                      \qedhere
    \end{align*}
  \end{proof}
\end{lemma}

\begin{lemma}[Elliptical Potential]\label{lemma:elliptical-potential}
  Let $x_1,\dotsc,x_n \in \Real^d$,
  $V_t = V_0 + \sum_{s=1}^t x_s \transp{x_s}$, $t\in[n]$, and
  $L \ge \max_t\norm{}{x_t}$. Then
  \begin{align*}
    \sum_{t=1}^n 1 \wedge \norm{\inv{V_{t-1}}}{x_t}^2
    &\le 2\log\frac{\det V_n}{\det V_0} \le 2d\log\frac{\tr V_0+nL^2}{d\det^{1/d} V_0}.
  \end{align*}

  \begin{proof}
    We use the fact that for any $u \ge 0$, $u \wedge 1 \le
    2\log(1+u)$, so that
    \begin{align*}
      \sum_{t=1}^n 1 \wedge \norm{\inv{V_{t-1}}}{x_t}^2
      &\le 2\sum_{t=1}^n \log(1 + \norm{\inv{V_{t-1}}}{x_t}^2).
    \end{align*}
    We will show that this last expression is $\log(\det V_n/\det
    V_0)$.  For $t \ge 1$ we have
    \begin{align*}
      V_t &= V_{t-1} + x_t\transp{x_t}
           = V_{t-1}^{1/2} (I + V_{t-1}^{-1/2}x_t\transp{x_t}V_{t-1}^{-1/2}) V_{t-1}^{1/2} \\
      \det V_t &= \det V_{t-1}\det(I + V_{t-1}^{-1/2}x_t\transp{x_t}V_{t-1}^{-1/2}).
    \end{align*}

    Consider the eigenvectors of the matrix $I+y\transp{y}$ for an
    arbitrary vector $y\in\Real^s$.  We know that $y$ itself is an
    eigenvector with eigenvalue $1+\norm{}{y}^2$:
    \begin{align*}
      (I + y\transp{y})y &= y + y\innerp{y}{y} = (1+\norm{}{y}^2)y.
    \end{align*}
    Moreover, since $I+y\transp{y}$ is symmetric, every other
    eigenvector $u$ is orthogonal to $y$, so that
    \begin{align*}
      (I + y\transp{y})u &= u + u\innerp{y}{u} = u.
    \end{align*}
    Therefore the only eigenvalues of $I+y\transp{y}$ are
    $1+\norm{}{y}^2$ (with eigenvector $y$) and 1.

    In our case $y = V_{t-1}^{-1/2}x_t$ and $\norm{}{y}^2 =
    \transp{x_t}\inv{V_{t-1}}x_t = \norm{\inv{V_{t-1}}}{x_t}^2$, so we get our
    first inequality:
    \begin{align*}
      \det V_n &= \det V_0 \prod_{t=1}^n(1 + \norm{\inv{V_{t-1}}}{x_t}^2) \\
      \log\frac{\det V_n}{\det V_0} &= \sum_{t=1}^n\log(1+\norm{\inv{V_{t-1}}}{x_t}^2).
    \end{align*}

    To get the second inequality, we apply the arithmetic-geometric
    mean inequality to the eigenvalues $\lambda_i$ of $V_n$:
    \begin{align*}
      \det V_n &= \prod_{i=1}^d \lambda_i
                \le \paren[\Big]{\frac{1}{d} \sum_{i=1}^d \lambda_i}^d
                = \paren{(1/d)\tr V_n}^d
                \le \paren{(\tr V_0 + nL^2)/d}^d \\
      \log\frac{\det V_n}{\det V_0}
              &\le d\log\frac{\tr V_0 + nL^2}{d\det^{1/d}V_0}
                \qedhere
    \end{align*}
  \end{proof}
\end{lemma}


\begin{theorem}[Generic LinUCB Regret]\label{thm:linucb-regret}
  Suppose \cref{assumption:linucb} holds with
  $0 \prec V_0 \in \Real^{d \times d}$ being symmetric positive
  semi-definite and $V_t = V_{t-1} + X_t\transp{X_t}$. Then, with
  probability $1-\delta$ the pseudo-regret
  \begin{align*}
    \widehat{R}_n &= \sum_{t=1}^n \max_{x\in\Dset{t}} \innerp{x}{\theta^*} - \innerp{X_t}{\theta*}
  \end{align*}
  of Linear UCB satisfies
  \begin{align*}
    \widehat{R}_n &\le \sqrt{8n\beta_{n-1} \log\frac{\det V_n}{\det V_0}}
                   \le \sqrt{8dn\beta_{n-1}\log\frac{\tr V_0 + nL^2}{d\det^{1/d} V_0}}
  \end{align*}

  \begin{proof}
    Combine \cref{lemma:linucb-regret,lemma:elliptical-potential}.
  \end{proof}

\end{theorem}


\section{Ellipsoidal Confidence Sets}
\label{sec:ellips-conf-bounds}

We will consider confidence sets for the value of $\theta^*$ that are
ellipsoidal with centre $\hat{\theta}$, of the form
$\set{\theta\in\Real^d \given \norm{V}{\theta-\hat{\theta}}^2 \le
  \beta}$.  Then the upper confidence bound of an action $x$ is
\begin{align*}
  \UCB(x) &= \max_{\theta: \norm{V}{\theta-\hat\theta}^2 \le \beta} \innerp{x}{\theta} \\
  \shortintertext{We solve this constrained optimization problem by the method of
  Lagrange multipliers:}
  \mathcal{L}(\theta, \lambda) &= \innerp{x}{\theta} - \lambda(\norm{V}{\theta-\hat\theta}^2 - \beta) \\
  \nabla_\theta\mathcal{L}(\theta, \lambda) &= \transp{x} - \lambda\transp{(\theta-\hat\theta)}V = 0 \\
  \theta &= \hat\theta + \frac{{\inv{V}x}}{\lambda} \\
  \shortintertext{To find $\lambda$:}
  \beta &= \norm{V}{\theta-\hat\theta}^2
          = \norm[\bigg]{V}{\frac{\inv{V}x}{\lambda}}^2
          = \frac{1}{\lambda^2}\transp{x}\inv{V}x \\
  \lambda &= \norm{\inv{V}}{x} / \sqrt\beta \\
  \shortintertext{Which we substitute into the expression above:}
  \UCB(x) &= \innerp[\bigg]{x}{\hat\theta + \frac{\sqrt\beta}{\norm{\inv{V}}{x}}\inv{V}x} \\
          &= \innerp{x}{\hat\theta} + \sqrt\beta \norm{\inv{V}}{x}.
\end{align*}
We have therefore shown that if we construct an ellipsoidal confidence
set with an appropriate $V$ and $\beta$, then the requirements of
\cref{assumption:linucb} will be satisfied with the above $\UCB$
index.

Let $X_s \in \Real^d$ be the action vector selected by the algorithm at
time $s$, so that $X$ is a $t \times d$ matrix (here we have fixed
some particular round $t \le n$).  The \emph{Gram matrix} is given by
$G \defeq \transp{X}X \in \Real^{d \times d}$.  Let $y_s$ be the reward
received at time $s$, so that $y\in\Real^t$.

We will take $\hat{\theta}$ to be a regularized solution of the
least-squares system
\begin{align*}
  X\theta &\approx y,
\end{align*}
regularized by the symmetric positive definite matrix $H \succeq 0$:
\begin{align*}
  \hat{\theta} &= \argmin_\theta \frac{1}{2}\norm{}{X\theta - y}^2 + \frac{1}{2}\norm{H}{\theta}^2 \\
               &= \inv{\paren{\transp{X}X + H}} \transp{X}y \\
               &= \inv{\paren{\transp{X}X + H}} \transp{X} \paren{X\theta^* + \eta} \\
               &= \theta^* + \inv{\paren{\transp{X}X + H}}\paren{\transp{X}\eta - H\theta^*} \\
               &= \theta^* + \inv{V}Z - \inv{V}H\theta^*
\end{align*}
where we used the fact that $y = X\theta^* + \eta$ (and $\eta_s$ is the
noise in the reward at round $s$) and we defined $V \defeq \transp{X}X
+ H$ and $Z\defeq X^T\eta$.

\begin{lemma}\label{lemma:subgaussian-z}
  Under \cref{assumption:subgaussian-noise} and for any
$\lambda\in\Real^d$, the random variable $Z = \transp{X}\eta$ satisfies
  \begin{align*}
    \Ex{\exp(\transp{\lambda}Z)} \le \exp\paren{\norm{G}{\lambda}^2/2}.
  \end{align*}

  \begin{proof}
    We have
    \begin{align*}
      \Ex{\exp(\transp{\lambda}Z)}
      &= \Ex{\exp(\transp{\lambda}\transp{X}\eta)} \\
      &= \Ex[\Big]{\Ex[\Big]{\prod_{s=1}^t \exp\paren{\transp{\lambda}X_s\eta_s} \given \mathcal{F}_t}} \\
      &= \Ex[\Big]{\Ex[\Big]{\exp\paren{\transp{\lambda}X_t\eta_t} \given \mathcal{F}_t} \prod_{s=1}^{t-1} \exp\paren{\transp{\lambda}X_s\eta_s}} \\
      &\le \Ex[\Big]{\exp\paren{{(\transp{\lambda}X_t)}^2/2} \prod_{s=1}^{t-1} \exp\paren{\transp{\lambda}X_s\eta_s}} \\
      &\le \Ex[\Big]{\prod_{s=1}^t\exp({(\transp{\lambda}X_s)}^2/2)} \\
      &= \Ex[\Big]{\exp\paren[\Big]{\sum_{s=1}^t\frac{\transp{\lambda}X_s\transp{X_s}\lambda}{2}}} \\
      &= \exp\paren[\Big]{\frac{1}{2}\transp{\lambda}\transp{X}X\lambda}
        = \exp(\norm{G}{\lambda}^2/2)
        \qedhere
    \end{align*}
  \end{proof}
\end{lemma}


\begin{lemma}\label{lemma:z-norm-bounded-whp}
  Suppose for any $\lambda\in\Real^d$ the random variable
  $Z=\transp{X}\eta$ satisfies
  $\Ex{\exp(\transp{\lambda}Z)} \le \exp(\norm{G}{\lambda}^2/2)$ (see,
  for example, \cref{lemma:subgaussian-z}).  Let
  $0 \prec H \in \Real^{d\times d}$ be any symmetric positive definite
  matrix.  Then for any $0 < \delta \le 1$, we have
  \begin{align*}
    \Prob[\Bigg]{\norm{\inv{(G+H)}}{Z} \ge \sqrt{2\log\frac{1}{\delta} + \log\frac{\det(G+H)}{\det H}}} &\le \delta.
  \end{align*}

  \begin{proof}
    We define
    \begin{align*}
      M_\lambda &\defeq \exp\paren[\Big]{\transp{\lambda}Z - \frac{1}{2}\transp{\lambda}G\lambda}.
    \end{align*}
    Now consider $\lambda\sim\mathcal{N}(0, \inv{H})$ to be a random
    variable with the density function $h(\lambda)$.  Define
    \begin{align*}
      \bar{M}
      &\defeq \int M_\lambda \,h(\lambda)\,d\lambda \\
      &= \frac{1}{\sqrt{{(2\pi)}^d \det\inv{H}}} \int\exp\paren[\Big]{\transp{\lambda}Z
        - \frac{1}{2}\transp{\lambda}G\lambda
        - \frac{1}{2}\transp{\lambda}H\lambda
        } \,d\lambda.
    \end{align*}
    We complete the square in the integrand:
    \begin{align*}
      \transp{\lambda}Z - \frac{1}{2}\transp{\lambda}G\lambda - \frac{1}{2}\transp{\lambda}H\lambda
      &= \frac{1}{2}\transp{Z}\inv{(G+H)}Z - \frac{1}{2}\transp{(\lambda - \inv{(G+H)}Z)}(G+H)(\lambda-\inv{(G+H)}Z) \\
      &= \frac{1}{2} \norm{\inv{(G+H)}}{Z}^2 - \frac{1}{2}\norm{G+H}{\lambda-\inv{(G+H)}Z}^2
    \end{align*}
    which we substitute into the previous equation to get
    \begin{align*}
      \bar{M}
      &= \frac{\exp\paren[\big]{\frac{1}{2} \norm{\inv{(G+H)}}{Z}^2}}{\sqrt{{(2\pi)}^d \det\inv{H}}}
        \int \exp\paren[\Big]{-\frac{1}{2} \norm{G+H}{\lambda-\inv{(G+H)}Z}^2} \,d\lambda \\
      &= \sqrt{\frac{\det H}{\det(G+H)}} \exp\paren[\Big]{\frac{1}{2}\norm{\inv{(G+H)}}{Z}^2}, \\
      \log\bar{M} &= \frac{1}{2}\norm{\inv{(G+H)}}{Z}^2 + \frac{1}{2}\log\frac{\det H}{\det(G+H)}.
    \end{align*}
    Our assumption gives us
    \begin{align*}
      \Ex{\exp(\transp{\lambda}Z)} &\le \exp\paren[\Big]{\frac{1}{2}\transp{\lambda}G\lambda} \\
      \Ex[\bigg]{\frac{\exp(\transp{\lambda}Z)}{\exp(\frac{1}{2}\transp{\lambda}G\lambda)}}
      &= \Ex{M_\lambda} \le 1, &\text{for all }\lambda\in\Real^d.
    \end{align*}
    Now, by Fubini's theorem we can exchange the expectation with the
    integral over $\lambda$:
    \begin{align*}
      \Ex{\bar{M}} &= \Ex[\Big]{\int M_\lambda\,h(\lambda)\,d\lambda} = \int \Ex{M_\lambda} \,h(\lambda)\,d\lambda \le 1
    \end{align*}
    and use a Chernoff bound:
    \begin{align*}
      \Prob{\log(\bar{M}) \ge u} &\le \exp(-u) \\
      \Prob[\Big]{\frac{1}{2}\norm{\inv{(G+H)}}{Z}^2 \ge u + \frac{1}{2}\log\frac{\det(G+H)}{\det H}} &\le \exp(-u) \\
      \Prob[\Big]{\norm{\inv{(G+H)}}{Z} \ge \sqrt{2u + \log\frac{\det(G+H)}{\det H}}} &\le \exp(-u).
    \end{align*}
    Substituting $u = \log(1/\delta)$ completes the proof.
  \end{proof}

\end{lemma}

%===============================================================================
% \hrule

% We see that
% \begin{align*}
%   \max_{\lambda\in\Real^d} \exp\paren[\Big]{\transp{\lambda}Z - \frac{1}{2}\transp{\lambda}G\lambda}
%   &= \exp\paren[\Big]{\max_{\lambda\in\Real^d} \transp{\lambda}Z - \frac{1}{2}\transp{\lambda}G\lambda}.
% \end{align*}
% The maximizer of this expression is given by taking the gradient and
% setting it to zero:
% \begin{align*}
%   \nabla_\lambda\brck[\Big]{\transp{\lambda}Z - \frac{1}{2}\transp{\lambda}G\lambda}_{\lambda=\lambda^*} = Z - G\lambda^* &= 0 \\
%   \lambda^* &= \inv{G}Z
% \end{align*}
% and thus
% \begin{align*}
%   \max_{\lambda\in\Real^d} \exp\paren[\Big]{\transp{\lambda}Z - \frac{1}{2}\transp{\lambda}G\lambda}
%   &= \exp\paren[\Big]{\transp{Z}\inv{G}Z - \frac{1}{2}\transp{Z}\inv{G}Z} \\
%   &= \exp\paren[\Big]{\frac{1}{2}\norm{\inv{G}}{Z}^2}.
% \end{align*}
% We define
% \begin{align*}
%   M_\lambda \defeq \exp\paren[\Big]{\transp{\lambda}Z - \frac{1}{2}\transp{\lambda}G\lambda}
% \end{align*}
% and use Chernoff's bound:
% \begin{align*}
%   \Pr\paren[\Big]{\frac{1}{2}\norm{\inv{G}}{Z}^2 > u}
%   &= \Pr\paren[\Big]{\max_{\lambda\in\Real^d}M_\lambda > u} \\
%   &\le \exp(-u) \Ex[\Big]{\max_{\lambda\in\Real^d} M_\lambda}.
% \end{align*}
% \hrule
%===============================================================================

\subsection{Ridge Regression}
\label{sec:ridge-regression}

We will now instantiate a concrete algorithm based on \emph{ridge
  regression}, i.e.\ using the regularizer $H=\rho I$ for some
$\rho>0$.  Thus we will have
\begin{align*}
  V_t &\defeq \rho I + \sum_{s=1}^t X_s\transp{X_s}\\
  \shortintertext{and}
  \hat{\theta}_t - \theta^* &= \inv{V_t}Z_t - \inv{V_t}H\theta^* \\
                          &= \inv{V_t}Z_t - \rho\inv{V_t}\theta^* \\
  V_t^{1/2}(\hat{\theta}_t - \theta^*) &= V_t^{-1/2}Z - \rho V_t^{-1/2}\theta^* \\
  \norm{V_t}{\hat{\theta}_t - \theta^*} &= \norm{}{V_t^{-1/2}Z - \rho V_t^{-1/2}\theta^*} \\
  &\le \norm{\inv{V_t}}{Z} + \rho\norm{\inv{V_t}}{\theta^*}.\
                          &\text{Triangle inequality} \\
  &\le \norm{\inv{V_t}}{Z} + \sqrt\rho \norm{}{\theta^*} &\text{Since } V_t \succeq \rho I.
\end{align*}
We now use \cref{lemma:subgaussian-z,lemma:z-norm-bounded-whp} in our
confidence bound:
\begin{align*}
  \Prob[\Bigg]{\norm{V_t}{\hat{\theta}_t - \theta^*} > \sqrt\rho\norm{}{\theta^*} + \sqrt{2\log\frac{1}{\delta} + \log\frac{\det V_t}{\det \rho I}}}
  &\le \delta.
\end{align*}
We assume that $\norm{}{\theta^*} \le S$.  We use the union bound,
replacing $\delta$ with $\delta/n$ to get a bound that holds uniformly
at every round:
\begin{align*}
  \sqrt{\beta_t} &= \sqrt\rho S + \sqrt{2\log\frac{n}{\delta} + \log\frac{\det V_t}{\det \rho I}}.
\end{align*}
Applying \cref{thm:linucb-regret} gives us the regret bound
\begin{align*}
  \widehat{R}_n
  &\le \sqrt{8dn\beta_{n-1}\log\frac{\tr V_0 + nL^2}{d\det^{1/d} V_0}}
    = \sqrt{8dn\beta_{n-1}\log\frac{d\rho + nL^2}{d\rho}} \\
  \shortintertext{where}
  \sqrt{\beta_{n-1}}
  &= \sqrt\rho S + \sqrt{2\log\frac{n}{\delta} + \log\frac{\det V_{n-1}}{\det \rho I}} \\
  &\le \sqrt\rho S + \sqrt{2\log\frac{n}{\delta} + d\log\paren*{1 + \frac{nL^2}{d\rho}}}.
\end{align*}
Choosing $\delta=1/n$ and constant $\rho$ gives $\sqrt{\beta_{n-1}} =
O(d^{1/2}\log^{1/2}(n/d))$ and thus the expected regret of Linear UCB
with ellipsoidal confidence sets satisfies
\begin{align*}
  \widehat{R}_n &= O(\beta_n^{1/2}\sqrt{dn\log(n/d)}) = O(d\log(n/d)\sqrt{n}).
\end{align*}

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
